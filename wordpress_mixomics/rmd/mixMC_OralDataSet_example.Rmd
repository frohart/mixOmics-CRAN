---
title: "mixMC Multilevel ORAL DATASET"
date: "22 November 2016"
output:
  html_document:
    code_folding: show
    highlight: haddock
    df_print: kable

---
```{r include=FALSE}
library(knitr)
knitr::opts_chunk$set(dpi = 100, echo= TRUE, warning=FALSE, message=FALSE, #dev = 'jpeg',
                      fig.show=TRUE, fig.keep = 'all', fig.width= 6)
```

# HMP Oral Data 16S

Here we apply mixMC to the Human Microbiome **Oral** 16S data set. In this data set we considered samples from oral cavity, which has been found to be as diverse as the stool microbiome. The nine oral sites were Attached Keratinising Gingiva, Buccal Mucosa, Hard Palate, Palatine Tonsils, Saliva, Subgingival Plaque, Supragingival Plaque, Throat and Tongue Dorsum. After prefiltering, the data include 1,562 OTU  for 73 unique patients and a total of 657 samples. 


Launch mixOmics, which can be downloaded on our website. 
<span style="color:red">Dont forget to update to the [latest mixOmics version](http://mixomics.org/category/news/)</span>

```{r global settings, include=TRUE, echo=TRUE, warning=FALSE, message=FALSE}
library(mixOmics)
```

# Data: Oral Data Set

The Oral data set used in this example can be dowloaded from the [mixMC](http://mixomics.org/example-of-multilevel-analysis-with-mixmc-hmb-2/) page.

```{r}
load('RData/HMP-Oral.RData')
```

# Filtering and Normalisation 

Using the Oral 16S data in this example we assume the data are prefiltered and normalised with TSS, see [Filtering and Normalisation](http://mixomics.org/mixmc/prefiltering-normalisation/) for more details. 

```{r, include=FALSE}
data.raw =data.raw + 1

low.count.removal = function(
                        data, # OTU count data frame of size n (sample) x p (OTU)
                        percent=0.01 # cutoff chosen
                        ){
    keep.otu = which(colSums(data)*100/(sum(colSums(data))) > percent)
    data.filter = data[,keep.otu]
    return(list(data.filter = data.filter, keep.otu = keep.otu))
}

result.filter = low.count.removal(data.raw, percent=0.01)
data = result.filter$data.filter

TSS.divide = function(x){
 x/sum(x)
}

data.TSS = t(apply(data, 1, TSS.divide))
```

Set up the outcome "Y" as a factor indicating the body sites of each sample and "sample" which indicates the unique ID of each repeated individual (repeated measures design). 

```{r}
# input the Y outcome, which is a factor indicating the body sites of each sample while sample a vector indicating the unique ID of each repeated individual
Y  =  as.factor(indiv$HMPbodysubsite)
summary(Y)
sample = as.factor(indiv$RSID) 
```

# Unsupervised Analsysis with PCA

PCA enables visualisation of diversity patterns in an unsupervised analysis. We need to specify the log ratio transformation (choose between ‘CLR’ or ‘ILR’) and specify a sufficient number of components to understand how the variation in the data is explained per component.

```{r}
pca.res = pca(X = data.TSS, ncomp = 10, logratio = 'ILR', multilevel = sample)
plot(pca.res)
```


The barplot above depicts the percentage of explained variance per component for a PCA. It is a good indicator of how many components to retain in the final PCA model. The sample plot below displays the samples colored according to Y, but note that PCA does not take Y into account in the analysis!



```{r pca-plot, fig.keep='all'}
# plotting the first components 
plotIndiv(pca.res,  comp = c(1,2), 
          pch = 16, ind.names = F, group = Y, col.per.group = color.mixo(1:9),
          legend = TRUE
          )
```



# Supervised Analysis and Selection of Discriminative OTUs with sPLS-DA

sPLS-DA performs variable (OTU) on each component, [see sPLS-DA for details](http://mixomics.org/methods/spls-da/).

## Tuning sPLS-DA

To choose the number of components for sPLS_DA we run the function perf() for a **PLS-DA** model with no variable selection (often, ncomp = K-1 where K is the number of categories in the outcome Y is sufficient, but depends on the data).

```{r}
#plsda
data.plsda <- plsda(X = data.TSS, Y, ncomp = nlevels(Y) - 1)
```
```{r plsda perf, eval=FALSE}
# check performance
perf.plsda <- perf(data.plsda, validation = 'Mfold', folds = 5,
                    progressBar = FALSE, nrepeat = 10)
```
```{r save file plsda, eval=FALSE, include=FALSE}
save(perf.plsda, file = 'RData/ORAL-perf-PLSDA.RData')
```
```{r load data plsda, include=FALSE}
load('RData/ORAL-perf-PLSDA.RData')
```

```{r plot perf.plsda}
plot(perf.plsda, overlay = 'measure', sd=TRUE)
```

Above is the plot of the classification error rate averaged across 5 folds and the 10 repeated CV for all prediction distances. BER stands for balanced error rate, which accounts for unbalanced number of samples per class. This step allows to choose the best prediction distance that will be input in the tune sPLS-DA step below.

```{r plsda 8 components}
plotIndiv(data.plsda , comp = c(1,2),
          group = Y, ind.names = FALSE, 
          ellipse = TRUE, legend = TRUE, title = 'Oral-16S, PLSDA comp 1 - 2')

```

We can observe better clusters than previously with the PCA analysis. This is to be expected since the PLS-DA model includes the class information of each individual. The sPLS-DA analysis will help refine the sample clusters and select a small subset of variables relevant to discriminate each class.

## Tuning sPLS-DA

The tuning of sPLS-DA is being performed one component at a time inside the function and the optimal number of variables to select is automatically retrieved for each component. We set ncomp = 5 and we used 10-fold cross validation (folds = 5 repeated 10 times). To ensure a stable result we advise to set nrepeat = 50-100. 

```{r tuning, eval=FALSE}
# set the tuning grid for some possible values of keepX
list.keepX<- c(5:10, seq(15, 50, 5), seq(60, 100, 10))
ncomp = 5 
splsda.tune = tune.splsda(data.TSS, Y, 
                          ncomp = 5, # (ncomp + 1)
                          test.keepX = list.keepX,
                          multilevel = sample,
                          logratio = 'CLR',
                          validation = 'Mfold',
                          folds = 5, dist = "centroids.dist", nrepeat = 10) #recomended between 50-100
# may show some convergence issues for some of the cases, it is ok for tuning
```

```{r saving sPLSDA, eval= FALSE, include=FALSE}
 save(splsda.tune, file = 'RData/ORAL-sPLSDA.RData')
```

```{r, include=FALSE}
#to save time load the data
load('RData/ORAL-sPLSDA.RData')
```
```{r}
# mean error rate across all CV folds and nrepeats
head(splsda.tune$error.rate)
# optimal keepX achieving lowest error rate
head(splsda.tune$choice.keepX)

plot(splsda.tune, optimal = TRUE, sd = TRUE)
```

The graphic above shows that the error rate decreases when more components are included in sPLS-DA. 

## sPLS-DA

We now run a sPLS-DA *multilevel analysis*. Note: with sPLS-DA we can only choose a CLR transformation.  

```{r splsda}
select.keepX = splsda.tune$choice.keepX #from tuning set above
select.ncomp = length(select.keepX)

res.splsda = splsda(X = data.TSS,
                    Y = Y,
                    multilevel = sample,
                    ncomp = 5,
                    keepX = select.keepX,
                    logratio= "CLR")
```


```{r splsda plotting}
#on the first two components
plotIndiv(res.splsda,
          comp =c(1,2),
          ind.names = FALSE, 
          col.per.group = color.mixo(1:9), # the number of groups 
          pch = 16, 
          ellipse = TRUE,
          legend = TRUE,
          title = 'ORAL, sPLSDA comp 1 - 2')
```

## Evaluating sPLS-DA

The classification performance of the sPLS-DA multilevel model can be assessed using the function *perf()*. The mean error rates per component are output and type of distance are output. The prediction distance can also be specified, see ?perf. 


```{r perf splsda, eval=FALSE}
#set seed
set.seed(34) 

splsda.perf = perf(res.splsda, validation = 'Mfold', folds = 5, 
                   progressBar = FALSE, nrepeat = 10)
```

```{r save perf splsda, include=FALSE, eval=FALSE}
save( splsda.perf, file = 'RData/ORAL-perf-sPLSDA.RData')
```
```{r load data}
load('RData/ORAL-perf-sPLSDA.RData')
```

```{r plotting splsda}
kable(head(splsda.perf$error.rate.class))

plot(splsda.perf)
```

```{r}
head(selectVar(res.splsda, comp = 1)$value)
```

## Contribution plots

The sPLS-DA selects the most discriminative OTUs that best characterize each body site indicated in Y. The contribution plots below displays the importance of each OTU in the sPLS-DA model and in which body site they are the most abundant (contrib = 'max'), according to the median (method = 'median'). Other options are available, see ?plotLoadings

```{r, fig.height= 8, fig.width=9}
#for component 1
plotLoadings(res.splsda, comp = 1, method = 'mean', contrib = 'max')
```

## Clustered Image Map 

We represent clustered image maps (with Euclidian distance, Ward linkage set by default) for the OTU selected on each sPLS-DA component. The abundance values that are displayed are the normalised, log ratio transformed values. All OTUs selected by the sPLS-DA model are displayed, other options can include a specific component, see ?cim. 

```{r cimplot, fig.height= 8, fig.width=9}
#for component 1
cim(res.splsda, comp = 1, row.sideColors = color.mixo(Y))
```

# References

1. [Lê Cao, K.-A., Boitard, S., Besse, P.: Sparse PLS Discriminant Analysis: biologically relevant feature selection and graphical displays for multiclass problems. BMC bioinformatics 12(1), 253 (2011)](https://scholar.google.com/scholar_url?url=http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-253&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&ei=y-g8WO2YMoKvjAHq1LHYDw&scisig=AAGBfm36JhKbmj5fZ9yykLKRPPqXYmyvPg)

2.  ---
title: "mixMC Multilevel HMP 16S Data"
output:
  pdf_document: default
  html_document:
    code_folding: show
    df_print: kable
    highlight: haddock
date: "22 November 2016"
---
# Human Microbiome Project 16s data 

Here we apply the mixMC framework on the Human Microbiome Most Diverse 16S data set, which includes OTU counts on the three most diverse bodysites: Subgingival plaque (Oral), Antecubital fossa (Skin) and Stool sampled from 54 unique individuals for a total of 162 samples.  The prefiltered dataset includes 1,674 OTU counts. The data were downloaded from the [Human Microbiome Project](http://hmpdacc.org/HMQCP/all/). The original data contained 43,146 OTU counts for 2,911 samples measured from 18 different body sites.

We focus here on the statistical exploration and analysis of the **repeated measurement** data set using multivariate projection-based approaches such as Principal Components Analysis (PCA) (data mining and exploration) and sparse Partial Least Squares Discriminant Analysis (sPLS-DA) (for identification of indicator species characterising each body site).

Launch mixOmics, which can be downloaded on our website. 
<span style="color:red">Dont forget to update to the [latest mixOmics version](http://mixomics.org/category/news/).</span>

```{r global_options, include=FALSE}
library(knitr)
knitr::opts_chunk$set(dpi = 100, echo= TRUE, warning=FALSE, message=FALSE, #dev = 'jpeg',
                      fig.show=TRUE, fig.keep = 'all', fig.width= 6)
```

```{r echo=TRUE, warning=FALSE, message=FALSE}
library(mixOmics)
```

# Data: Most Diverse Data Set

Using the NIH Human Microbial Project 16S data in this example we assume the data are prefiltered and normalised with TSS, as described in [mixMC normalisation](http://mixomics.org/mixmc/filtering-normalisation/).

```{r echo=TRUE}
data("diverse.16S")

# the 16S normalised data
data.mixMC = diverse.16S$data.TSS
```

We set up the outcome "Y" which is a factor indicating the body sites of each sample and "sample" which indicates the unique ID of each repeated individual (repeated measures design). 

```{r echo=TRUE, results="hide"}
# the outcome 
Y = diverse.16S$bodysite
# unique ID of each individual for multilevel analysis
sample = diverse.16S$sample
```
# Unsupervised Analsysis with PCA

Using unsupervised PCA allows for dimension reduction of the data and visualisation of diversity patterns in microbiome studies. Because we are using compositional data spurious results can arise if data is not transformed into Euclidean space. Therefore the data must be transformed using either [ILR](http://mixomics.org/mixmc/filtering-normalisation/) or [CLR](http://mixomics.org/mixmc/filtering-normalisation/). 

Here we chose the TSS normalisation ILR transformation as advised by Filmozer et al. [1]. The ‘CLR’ log ratio transformation can be used (faster, but slightly different results by changing the parameter to logratio = “CLR”).
```{r echo=FALSE, results="hide"}
dev.off()
```

```{r echo=TRUE,results = 'hide'}
pca.res = pca(data.mixMC, ncomp = 10, logratio = 'CLR', multilevel = sample)
#pca.res
plot(pca.res)
```

The PCA plot indicates that 2 components are sufficient to explain most of the variation in the data. 

* *You can play around with the log ratio transformations or use different normalisation (CSS), and multilevel vs non multilevel to see the benefit of taking into account the repeated measures design in the PCA model. 

```{r echo=TRUE}
plotIndiv(pca.res, 
          comp = c(1,2), # the components to plot
          pch = 16, 
          ind.names = F, 
          group = Y, 
          col.per.group = color.mixo(1:3),
          legend = TRUE)
```

We can observe a natural separation between those (very diverse) body sites. Next we hope to find out which OTUs drive this separation.

# Supervised Analysis and Selection of Discriminative OTUs with sPLS-DA

The mixMC frameworks uses the sPLS-DA multivariate analysis from mixOmics[3]. The sPLS-DA selects the most discriminative OTUs that best characterize each body site, [see sPLS-DA](http://mixomics.org/methods/spls-da/). 

Firstly, to choose the number of components for sPLS_DA we run the function perf() for a **PLS-DA** model with no variable selection (often, ncomp = K-1 where K is the number of categories in the outcome Y is sufficient, but depends on the data). We choose 5-fold cross-validation repeated 10 times. To obtain a more reliable estimation of the error rate, the number of repeats should be increased (between 50 to 100). 

```{r}
plsda <- plsda(X = data.mixMC, Y, ncomp = nlevels(Y) - 1)

perf.plsda <- perf(plsda, validation = 'Mfold', folds = 5,
                    progressBar = FALSE, nrepeat = 10)

plot(perf.plsda, overlay = 'measure', sd=TRUE)
```

```{r}
plotIndiv(plsda , comp = c(1,2), ind.names = FALSE, 
          ellipse = TRUE, legend = TRUE, title = 'HMP Most Diverse, PLSDA comp 1 - 2')
```

## Tuning sPLS-DA

The parameters to choose in sPLS-DA are the number of variables to select (keepX) and the number of components (ncomp) and to do this we used the function tune.splsda(). In this example the sPLS-DA tuning step is performed on 3 components, using 5-fold validation repeated 10 times.

The tune.splsda() needs to be performed prior to the sPLS-DA analysis to choose the parameters on a grid of keepX values (make sure you choose the appropriate M fold cross-validation and provide sufficient nrepeat = 50 in the evaluation model, except for ‘loo’ where it is run on 1 repeat), also check the stability of the features selected during the cross-validation process.

```{r tune splsda, eval = FALSE, echo = TRUE}
 # this chunk takes ~ 12 min to run
splsda.tune = tune.splsda(data.mixMC, Y, ncomp = 3, multilevel = sample,
                           logratio = 'CLR',
                           test.keepX = c(seq(5,150, 5)), validation = 'Mfold', 
                           folds = 5, dist = 'max.dist', nrepeat = 10)
# may show some convergence issues for some of the cases, it is ok for tuning
```

```{r echo=TRUE, results='hide'}
# To gain some computing time on the tuning, directly load the data
load('RData/mixMC-tune-sPLSDA.RData')
kable(head(splsda.tune$error.rate))
plot(splsda.tune)

# optimal number of variables to select on 3 comps:
select.keepX = splsda.tune$choice.keepX[1:3]

select.keepX

```


The graphic above shows that the error rate decreases when more components are included in sPLS-DA.


## sPLS-DA

We now run a sPLS-DA multilevel analysis. **Note:** with sPLS-DA we can only choose a CLR transformation (see details [here](https://scholar.google.com/scholar_url?url=http://biorxiv.org/content/biorxiv/early/2016/03/16/044206.full.pdf&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&ei=0dA7WPvyNIKvjAHq1LHYDw&scisig=AAGBfm04GmTLnXd5EizkZPC1ZlPH9IRsfA).



```{r, echo=TRUE}
splsda.res <- splsda(data.mixMC, Y, ncomp = 3, keepX = select.keepX) 

plotIndiv(splsda.res, comp = c(1,2),
          ind.names = FALSE, 
          ellipse = TRUE, legend = TRUE,
          title = 'HMP Most Diverse, sPLSDA comp 1 - 2')
```


## Evaluating sPLS-DA

The classification performance of the sPLS-DA multilevel model can be assessed using the function *perf()*. The mean error rates per component are output and type of distance are output.

```{r Evaluating sPLS-DA, echo=TRUE}
# setting the seed so we get the same results with participants:
set.seed(34) 

splsda.perf = perf(splsda.res, validation = 'Mfold', folds = 5, 
                   progressBar = FALSE, nrepeat = 10)
splsda.perf$error.rate

plot(splsda.perf)
```

## Contribution plots

The sPLS-DA selects the most discriminative OTUs that best characterize each body site. The contribution plots below display the abundance of each OTU (large abundance = large absolute value) and in which body site they are the most abundant for each sPLS-DA component. The contribution plots need to be interpreted in combination with the sample plot below to understand the similarities between body sites, in addition to 'which bacteria characterize those body sites?'

<br>
The code below outputs the first selected OTUs and their coefficient (from the loading vector) on the first component:

```{r echo=TRUE, include= TRUE}
head(selectVar(splsda.res, comp = 1)$value) 
```

<br>

```{r splsa plots}
par(mfrow=c(1,3))

plotLoadings(splsda.res, comp = 1, method = 'mean', contrib = 'max')
```

## Clustered Image Map 

```{r CIM, fig.height= 8, fig.width= 8}
#CIM plot
cim(splsda.res, row.sideColors = color.mixo(Y))
```

# References

1. [Filzmoser, P., Hron, K., Reimann, C.: Principal component analysis for compositional data with outliers. Environmetrics 20(6), 621–632 (2009)](https://scholar.google.com/scholar_url?url=https://www.researchgate.net/profile/Peter_Filzmoser/publication/227528968_Principal_component_analysis_of_compositional_data_with_outliers/links/09e4151129a8c792bd000000.pdf&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&ei=4ZA7WO-bGMyT2AaosKqwDQ&scisig=AAGBfm1mB8frALUL699TNp-vVgk-XzGhOg)

2. [Le Cao KA, Costello ME, Lakis VA, Bartolo F, Chua XY, et al. (2016) MixMC: A Multivariate Statistical Framework to Gain Insight into Microbial Communities. PLOS ONE 11(8): e0160169. doi: 10.1371/journal.pone.0160169](http://journals.plos.org/plosone/article/metrics?id=10.1371/journal.pone.0160169)


3. [Le Cao, K.A., Boitard, S. and Besse, P., 2011. Sparse PLS discriminant analysis: biologically relevant feature selection and graphical displays for multiclass problems. BMC bioinformatics, 12(1), p.1.](https://scholar.google.com/scholar_url?url=http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-253&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&ei=7dA7WJCXNI6SjAHp3L6IAg&scisig=AAGBfm36JhKbmj5fZ9yykLKRPPqXYmyvPg)

